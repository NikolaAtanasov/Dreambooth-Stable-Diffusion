{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Wj_qNCDPBim3",
        "j-NDkFmifhLq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DreamBooth RunPod Notebook\n",
        "\n",
        "Run Notebook on a machine with sufficient GPU VRAM.\n",
        "\n",
        "### To run this notebook in RunPod:\n",
        "```\n",
        "!git clone https://github.com/NikolaAtanasov/Dreambooth-Stable-Diffusion\n",
        "```\n",
        "\n",
        "Forked from:\n",
        "https://github.com/JoePenna/Dreambooth-Stable-Diffusion/blob/main/dreambooth_runpod_joepenna.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "418nFBzu326y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.  Build Environment\n",
        "Most packages should already be installed if instancce is a SD template"
      ],
      "metadata": {
        "id": "UxB5D9eh4XAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Dreambooth-Stable-Diffusion\n",
        "\n",
        "!pip install omegaconf\n",
        "!pip install einops\n",
        "!pip install pytorch-lightning==1.6.5\n",
        "!pip install test-tube\n",
        "!pip install transformers\n",
        "!pip install kornia\n",
        "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install pillow==9.0.1\n",
        "!pip install torchmetrics==0.6.0\n",
        "!pip install -e .\n",
        "!pip install protobuf==3.20.1\n",
        "!pip install gdown\n",
        "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\"\n",
        "!pip install huggingface_hub\n",
        "!pip install ipywidgets==7.7.1\n",
        "!pip install captionizer==1.0.1\n",
        "# additional\n"
      ],
      "metadata": {
        "id": "Xdt_fBcW4eU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Download model (a or b)"
      ],
      "metadata": {
        "id": "Ur6_EWLr5WZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.a Download model from GDrive\n",
        "Right-click on the .ckpt file in GDrive, \"Get link\", set the link access for anyone with the link, copy the id of the file from the url (between /d/{file id}/view) and paste it in the cell below"
      ],
      "metadata": {
        "id": "28x2XnpyBVvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id="
      ],
      "metadata": {
        "id": "Uc9ESc9A5ZPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.b Download model from Hugging Face (TODO)"
      ],
      "metadata": {
        "id": "Wj_qNCDPBim3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set API token"
      ],
      "metadata": {
        "id": "XbsSrVHJBoO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download desired model - provide list"
      ],
      "metadata": {
        "id": "fwuEwLt8Bm9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Regularization images (a or b)"
      ],
      "metadata": {
        "id": "d9dGHj0I6Dtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.a Either download pre-generated regularization images\n",
        "`man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5   \n",
        "`man_unsplash` - pictures from various photographers   \n",
        "`person_ddim` `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0   \n",
        "`person_ddim` is recommended"
      ],
      "metadata": {
        "id": "LPaptk89fyDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download Regularization Images\n",
        "\n",
        "dataset=\"person_ddim\" #@param [\"man_euler\", \"man_unsplash\", \"person_ddim\", \"woman_ddim\", \"blonde_woman\"]\n",
        "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}"
      ],
      "metadata": {
        "id": "hCUyTd1Df4VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.b Or generate class images\n",
        "Training teaches your new model both your token **but** re-trains your class simultaneously.\n",
        "\n",
        "From cursory testing, it does not seem like reg images affect the model too much. However, they do affect your class greatly, which will in turn affect your generations.\n",
        "\n",
        "You can either generate your images here, or use the repos below to quickly download 1500 images."
      ],
      "metadata": {
        "id": "j-NDkFmifhLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATE 200 images - Optional\n",
        "self_generated_files_prompt = \"person\" #@param {type:\"string\"}\n",
        "self_generated_files_count = 200 #@param {type:\"integer\"}\n",
        "\n",
        "!python scripts/stable_txt2img.py \\\n",
        " --seed 10 \\\n",
        " --ddim_eta 0.0 \\\n",
        " --n_samples 1 \\\n",
        " --n_iter {self_generated_files_count} \\\n",
        " --scale 10.0 \\\n",
        " --ddim_steps 50 \\\n",
        " --ckpt model.ckpt \\\n",
        " --prompt {self_generated_files_prompt}\n",
        "\n",
        "dataset=self_generated_files_prompt\n",
        "\n",
        "!mkdir -p regularization_images/{dataset}\n",
        "!mv outputs/txt2img-samples/*.png regularization_images/{dataset}"
      ],
      "metadata": {
        "id": "V5LPIVIf6I7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Upload training images\n",
        "Upload 10-20 images of the target to:  /workspace/Dreambooth-Stable-Diffusion/training_images   \n",
        "WARNING: Be sure to upload an *even* amount of images, otherwise the training inexplicably stops at 1500 steps.\n",
        "*   2-3 full body\n",
        "*   3-5 upper body\n",
        "*   5-12 close-up on face\n",
        "\n",
        "The images should be as close as possible to the kind of images you're trying to make"
      ],
      "metadata": {
        "id": "kYKQb8r96JYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir ./training_images"
      ],
      "metadata": {
        "id": "jNVyoS786Nbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drag and drop selected images to the new training_images folder.   \n",
        "(Should be an even number of 512x512 PNG images)"
      ],
      "metadata": {
        "id": "Q9Wr968wm1tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Training\n"
      ],
      "metadata": {
        "id": "VC7nZAeV6UG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown This isn't used for training, just to help you remember what your trained into the model.\n",
        "project_name = \"project_name\" #@param {type:\"string\"}\n",
        "\n",
        "# MAX STEPS\n",
        "#@markdown ~100-200 x N (N = number of training images provided)\n",
        "max_training_steps = 2000 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Match class_word to the category of the regularization images you chose above.\n",
        "class_word = \"person\" #@param [\"man\", \"person\", \"woman\"] {allow-input: true}\n",
        "\n",
        "#@markdown This is the unique token you are incorporating into the stable diffusion model.\n",
        "token = \"firstNameLastName\" #@param {type:\"string\"}\n",
        "reg_data_root = \"/content/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
        "\n",
        "!rm -rf training_images/.ipynb_checkpoints\n",
        "!python \"main.py\" \\\n",
        " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
        " -t \\\n",
        " --actual_resume \"model.ckpt\" \\\n",
        " --reg_data_root \"{reg_data_root}\" \\\n",
        " -n \"{project_name}\" \\\n",
        " --gpus 0, \\\n",
        " --data_root \"/content/Dreambooth-Stable-Diffusion/training_images\" \\\n",
        " --max_training_steps {max_training_steps} \\\n",
        " --class_word \"{class_word}\" \\\n",
        " --token \"{token}\" \\\n",
        " --no-test"
      ],
      "metadata": {
        "id": "apQqbphogVzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Troubleshooting\n",
        "\n",
        "CUDA out of memory: open a new terminal, `ps aux` to check running processes, `kill` \"launcher\" and \"webui\" related ones (usually 11, 25, 26)"
      ],
      "metadata": {
        "id": "mIsPqaOFozNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Copy and name the checkpoint file"
      ],
      "metadata": {
        "id": "6zfWe7_JltFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory_paths = !ls -d logs/*\n",
        "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
        "training_images = !find training_images/*\n",
        "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
        "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
        "\n",
        "file_name = file_name.replace(\" \", \"_\")\n",
        "\n",
        "!mkdir -p trained_models\n",
        "!mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
        "\n",
        "print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")"
      ],
      "metadata": {
        "id": "XWBJxoVblw8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Upload model to Google Drive"
      ],
      "metadata": {
        "id": "47s5lVnWlyaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp trained_models/{file_name} /content/drive/MyDrive/{file_name}"
      ],
      "metadata": {
        "id": "-FcQT4oGl2oi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}